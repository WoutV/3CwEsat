\documentclass[a4paper, 12pt, titlepage]{report}

%Taal: Nederlands ("Inhoudsopgave", "Hoofdstuk",...)
\usepackage[dutch]{babel}
\usepackage{graphicx}
\usepackage{subcaption}

%Geen nummering bij secties en hoofdstukkden
\setcounter{secnumdepth}{-1} 

%geen indents
\setlength\parindent{0pt}

\usepackage[dutch]{babel}
\begin{document}

\title{\textbf{Numerieke Modellering en Benadering}\\\textit{Practicum 1: Eigenwaardenproblemen}\\}
\author{De Wolf Peter\\ Vekemans Wout}

\date{\today}
\begin{titlepage}
	\maketitle
	\thispagestyle{empty}
\end{titlepage}

\newpage

\listoffigures

\newpage

\section{Inleiding}
In dit practicum onderzoeken we methoden voor het bepalen van eigenwaarden van vole matrices. In een eerste sectie beschouwen we enkele theoretische eigenschappen van de methoden. In een tweede sectie worden de convergentie-eigenschappen van da methoden onderzocht aan de hand van MATLAB-experimenten. In de derde en laatste sectie gaan we dieper in op \'e\'en van de methoden, namelijk de Jacobi-methode.
\section{Theoretische eigenschappen}

\subsection{Opgave 1}

\subsection{Opgave 2}

\section{Convergentie-experimenten}
Voor al deze experimenten wordt gebruik gemaakt van een volle, re\"ele symmetrische matrix A. We laden hiervoor de gegeven matrix $mat1.txt$ in in MATLAB.

\subsection{Opgave 4}
Het uitvoeren van het $spy$-commando laat zien dat er geen enkel $non-zero$ element in de matrix zit. De uitvoering van het QR-algoritme op een matrix met die afmetingen (nog steeds relatief klein) zou zeer veel werk vragen. \\
Na het reduceren tot Hessenberg vorm zien we dat alle elementen onder de eerste benedendiagonaal nul zijn geworden. Verdere analyse leert ons dat ook de elementen boven de eerste bovendiagonaal allemaal van grootteorde $\epsilon_{mach}$ zijn. Als we de Hessenberg vorm van de matrix afronden tot op 15 decimalen verkijgen we een tridiagonale matrix.(zie figuur \ref{hessenberg}) Dit komt doordat de originele matrix symmetrisch was. De reductie naar Hessenberg vorm zorgt ervoor dat het algoritme niet op een volledige matrix moet inwerken. Het uitvoeren van het QR-algoritme vraagt nu slechts $\mathcal{O}(n^2)$ flops. 
\begin{figure}[!h]
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=\textwidth]{structuur_hessenberg.eps}
\subcaption{zonder afronden}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=\textwidth]{afgerond.eps}
\subcaption{met afronden}
\end{subfigure}

\caption{Structuur van de Hessenberg matrix}
\label{hessenberg}
\end{figure}

\subsection{Opgave 5}
Na uitvoeren van de drie methoden verkrijgen we ...... TODO we zien duidelijk dat het QR-algoritme zonder shifts een lineaire convergentie heeft. \\

Als maat voor de convergentie gebruiken we de relatieve fout op de berekende eigenwaarden. \\

Voor het algoritme zonder shifts stemt dit volledig overeen met de theorie. Theorem 28.4 (p. 218 in het handboek) geeft duidelijk aan dat bij het gebruik van QR zonder shifts $A^{(k)}$ lineair convergeert naar een diagonaalmatrix met de eigenwaarden van $A$ als elementen.
\begin{center}
\begin{table}
\caption[Relatieve fout op de vijf grootste berekende eigenwaarden]

\begin{tabular}{r||r|r|r|r|r}

Iteratie & 23 & 22& 21&20&19 \\
\hline
5	&	3.4173E-02	&	7.7106E-02	&	7.8187E-02	&	6.4348E-02	&	1.6090E-02	\\
10	&	1.7414E-02	&	1.5644E-02	&	5.4016E-02	&	2.7533E-02	&	3.4097E-03	\\
15	&	1.1828E-02	&	7.6086E-03	&	2.5512E-02	&	2.6705E-02	&	1.8666E-02	\\
20	&	8.1546E-03	&	7.6596E-03	&	1.4755E-02	&	1.9487E-02	&	2.2061E-02	\\
25	&	5.5253E-03	&	5.5328E-03	&	9.3537E-03	&	1.1783E-02	&	1.6347E-02	\\
30	&	3.6818E-03	&	3.7494E-03	&	5.9809E-03	&	7.2101E-03	&	1.1119E-02	\\
35	&	2.4229E-03	&	2.4821E-03	&	3.7863E-03	&	4.3930E-03	&	7.2111E-03	\\
40	&	1.5805E-03	&	1.6235E-03	&	2.3726E-03	&	2.6464E-03	&	4.5407E-03	\\
45	&	1.0249E-03	&	1.0543E-03	&	1.4757E-03	&	1.5767E-03	&	2.8068E-03	\\
50	&	6.6195E-04	&	6.8157E-04	&	9.1340E-04	&	9.3132E-04	&	1.7155E-03	\\
55	&	4.2643E-04	&	4.3936E-04	&	5.6357E-04	&	5.4674E-04	&	1.0413E-03	\\
60	&	2.7425E-04	&	2.8270E-04	&	3.4703E-04	&	3.1955E-04	&	6.2951E-04	\\
65	&	1.7618E-04	&	1.8169E-04	&	2.1342E-04	&	1.8615E-04	&	3.7964E-04	\\
70	&	1.1310E-04	&	1.1668E-04	&	1.3115E-04	&	1.0814E-04	&	2.2861E-04	\\
75	&	7.2573E-05	&	7.4891E-05	&	8.0558E-05	&	6.2672E-05	&	1.3754E-04	\\
80	&	4.6554E-05	&	4.8055E-05	&	4.9466E-05	&	3.6236E-05	&	8.2704E-05	\\
85	&	2.9857E-05	&	3.0829E-05	&	3.0368E-05	&	2.0900E-05	&	4.9712E-05	\\
90	&	1.9147E-05	&	1.9775E-05	&	1.8641E-05	&	1.2024E-05	&	2.9873E-05	\\
95	&	1.2277E-05	&	1.2683E-05	&	1.1442E-05	&	6.8983E-06	&	1.7948E-05	\\

\end{tabular}
\end{table}
\end{center}



\subsection{Opgave 6}

\subsection{Opgave 7}

\section{Alternatieve eigenwaardenalgoritmen}

\subsection{Opgave 8}

\subsection{Opgave 9}

\subsection{Opgave 10}

\end{document}
